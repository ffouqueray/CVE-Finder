import requests, re, math, datetime
from bs4 import BeautifulSoup

def NISTscrap(categorie, value, debut, fin):
    base_url = "https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&queryType=phrase&search_type=all"
    if value is not None :
        value = value.lower()
        value = value.replace(" ", "_") # Afin d'avoir un résultat lisible pour NIST, on doit transformer la variable value (ex : de Windows 10 on passe à windows_10)

    # On sélectionne le type de produit en fonction du résultat de CVEDetails
    if categorie == "Products" :
        base_url += f"&isCpeNameSearch=false&cpe_product=cpe%3A%2F%3A%3A{value}"
    elif categorie == "Vendors" :
        base_url += f"&isCpeNameSearch=false&cpe_vendor=cpe%3A%2F%3A{value}"
    elif categorie == "CVEs" :
        base_url += f"&cve_id={value}"
    
    if debut is not None : # On ajoute les dates s'il y en a
        base_url += f"&isCpeNameSearch=false&pub_start_date={debut.strftime('%m')}%2F{debut.strftime('%d')}%2F{debut.strftime('%Y')}&pub_end_date={fin.strftime('%m')}%2F{fin.strftime('%d')}%2F{fin.strftime('%Y')}"

    # On fait une requete pour récupérer le contenu et on l'intègre dans BS4
    coverpage = requests.get(base_url).content
    soup = BeautifulSoup(coverpage, 'html5lib')

    # On scrap le nombre de vulnérabilités trouvées puis on demande à l'utilisateur combien il en veut
    vulnerabilities = int(soup.find(attrs={"class": "col-sm-12 col-lg-3"}).strong.text.replace(',', ''))

    if vulnerabilities > 1 :
        choix = None
        while choix is None :
            try:
                choix = int(input(f"\n{vulnerabilities} vulnérabilités ont été trouvées\nCombien voulez-vous en récupérer ?\nVotre choix : "))
                if choix < 1 or choix > vulnerabilities :
                    raise Exception
            except:
                print(f"\nVous n'avez pas entré un nombre dans l'intervale 1-{vulnerabilities}.\nMerci de réessayer.\n")
                choix = None
    
    elif vulnerabilities == 1 :
        choix = 1
    else :
        return None
    
    # Si l'utilisateur en demande + que 20, alors je check le nombre de requetes que l'on aura à faire (20 résultats par page)
    if choix > 20:
        pages = math.ceil(choix / 20)
        nombre_CVE = []
        for x in range(pages-1):
            nombre_CVE.append(20)
        nombre_CVE.append(choix % 20)
    
    else:
        pages = 1
        nombre_CVE = [choix]

    # On boucle et on met tout ça dans une liste (utile pour un résultat en json)
    CVEs = []
    for i in range(pages):
        page = f"&startIndex={i*20}"
        coverpage = requests.get(f"{base_url}{page}").content
        soup = BeautifulSoup(coverpage, 'html5lib')

        for x in range(nombre_CVE[i]):
            ligne = soup.find("tr", attrs={"data-testid": f"vuln-row-{x}"}) # On check les 20 lignes de résultat de la page

            title = ligne.find("a", attrs={"data-testid": f"vuln-detail-link-{x}"}) # On récupère le lien (et le texte)
            description = ligne.find("p", attrs={"data-testid": f"vuln-summary-{x}"}) # On récupère la description

            date = ligne.find(attrs={"data-testid": f'vuln-published-on-{x}'}).text # On récupère la date et la met en datetime object pour la remettre comme on veut
            date = date.split(' -')[0]
            date = datetime.datetime.strptime(date, '%B %d, %Y; %I:%M:%S %p')

            cvss = ligne.find("td", attrs={"nowrap": "nowrap"}).text # On parse les scores CVSS 3 et CVSS 2. Besoin d'un regex pour faire une liste en séparant par 2 espaces ou +
            cvss = cvss.strip()
            cvss = re.split(r'\s{2,}', cvss)
            for x in range(len(cvss)):
                cvss[x] = cvss[x].split(':')
                cvss[x][1] = cvss[x][1].strip()
            
            # On ajoute tout ça dans notre liste pour ensuite avoir un fichier réutilisable
            CVEs.append(
                {
                    "name": title.text,
                    "link": f"https://nvd.nist.gov{title['href']}",
                    "description": description.text,
                    "CVSS score" : {
                        cvss[0][0]: cvss[0][1],
                        cvss[1][0] : cvss[1][1]
                    },
                    "published": date.strftime('%d/%m/%Y - %H:%M:%S')
                }
            )

    return CVEs